{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foundations of Machine Learning Aug-Nov 2024\n",
    "##### Sakshi Badole CS24MTECH11008\n",
    "##### Assignment 4\n",
    "Question 5: __Logistic Regression__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-entropy error as the error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y, y_hat):\n",
    "    m = y.size\n",
    "    return -1/m * (np.dot(y, np.log(y_hat)) + np.dot(1 - y, np.log(1 - y_hat)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate, num_iterations, tolerance):\n",
    "    \n",
    "    m = y.size\n",
    "    previous_cost = float('inf')\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, theta)\n",
    "        y_hat = sigmoid(z)\n",
    "        error = y_hat - y\n",
    "        gradient = np.dot(X.T, error) / m\n",
    "        theta -= learning_rate * gradient\n",
    "\n",
    "        # Compute the cost\n",
    "        cost = compute_cost(y, y_hat)\n",
    "\n",
    "\n",
    "        # Check for convergence\n",
    "        if abs(previous_cost - cost) < tolerance:\n",
    "            print(f\"\\nConvergence reached at iteration {i + 1}\")\n",
    "            break\n",
    "        \n",
    "        previous_cost = cost\n",
    "\n",
    "        if i == 0:\n",
    "            # Print the model equation after one iteration\n",
    "            print(\"\\nWeights after one iteration (θ₀, θ₁, θ₂):\", theta)\n",
    "            print(\"\\nUpdated logistic regression model after one iteration:\")\n",
    "            print(f\"P(y=1|x₁,x₂) = 1 / (1 + exp(-({theta[0]:.3f} + {theta[1]:.3f}x₁ + {theta[2]:.3f}x₂)))\")\n",
    "\n",
    "        if i == num_iterations-1 :\n",
    "            print(f\"Iteration {i + 1}: Cost = {cost}, Weights = {theta}\")    \n",
    "\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "\n",
    "    z = np.dot(X, theta)\n",
    "    y_hat = sigmoid(z)\n",
    "    return (y_hat >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    true_positive = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    true_negative = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    false_positive = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    false_negative = np.sum((y_pred == 0) & (y_true == 1))\n",
    "\n",
    "    accuracy = (true_positive + true_negative) / len(y_true)\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[0.346, 0.780],\n",
    "                        [0.303, 0.439],\n",
    "                        [0.358, 0.729],\n",
    "                        [0.602, 0.863],\n",
    "                        [0.790, 0.753],\n",
    "                        [0.611, 0.965]])\n",
    "y_train = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model with learning rate 0.1 and Initial weights as  $θ_{0}$ = −1, $θ_{1}$ = 1.5, $θ_{2}$ = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights after one iteration (θ₀, θ₁, θ₂): [-1.00316626  1.50535086  0.50196867]\n",
      "\n",
      "Updated logistic regression model after one iteration:\n",
      "P(y=1|x₁,x₂) = 1 / (1 + exp(-(-1.003 + 1.505x₁ + 0.502x₂)))\n",
      "\n",
      "Convergence reached at iteration 2\n"
     ]
    }
   ],
   "source": [
    "# Add intercept term\n",
    "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "\n",
    "# Initial weights\n",
    "theta = np.array([-1, 1.5, 0.5])\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "num_iterations = 1500\n",
    "\n",
    "# Train the model\n",
    "theta = gradient_descent(X_train, y_train, theta, learning_rate, num_iterations, tolerance=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights after one iteration \n",
    "***(θ₀, θ₁, θ₂): [-1.00316626  1.50535086  0.50196867]***\n",
    "\n",
    "### Updated logistic regression model after one iteration:\n",
    "***P(y=1|x₁,x₂) = 1 / (1 + exp(-(-1.003 + 1.505x₁ + 0.502x₂)))***\n",
    "\n",
    "Convergence reached at iteration 2 (tolerance value was 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the logistic regression model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "X_test = np.array([[0.959, 0.382],\n",
    "                    [0.750, 0.306],\n",
    "                    [0.395, 0.760],\n",
    "                    [0.823, 0.764],\n",
    "                    [0.761, 0.874],\n",
    "                    [0.844, 0.435]])\n",
    "y_test = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# Add intercept term to test data\n",
    "X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "\n",
    "# Make predictions\n",
    "predictions = predict(X_test, theta)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(y_test, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for test set:\n",
      "Predicted labels: [1 1 0 1 1 1]\n",
      "True labels:      [0 0 0 1 1 1]\n",
      "\n",
      "Accuracy: 0.667\n",
      "Precision: 0.600\n",
      "Recall: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nPredictions for test set:\")\n",
    "print(\"Predicted labels:\", predictions)\n",
    "print(\"True labels:     \", y_test)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
